- Consider a scenario where you are a developer who is tasked with creating a new feature for a web application being hosted on EC2. The web application is an online store and right now all of the items being sold in the store are loaded into a database manually behind the scenes. By manually, means there is a person who adds each row into a database for each new item to be sold in the store. This process takes a long time and isn't very scalable, and on top of that it's also prone to error. You are tasked with automating this process of getting new item information loaded into the inventory database.The goal is to have a person upload an inventory spreadsheet into Amazon S3, the object storage service, then have a process automatically load the data into the inventory database. What compute service would you use to host the processing logic to load the items from the file into the database?

    - You could have decided to use Amazon EC2 here. You could spin up a new instance specifically for this process and write some code that pulls the location of the spreadsheet for a new upload every so often, updating the database when it finds a new file. That would work. 
    - But before making the answer final here, I have a question. How often does new inventory get added to the database? -  New inventory gets updated one time per quarter. 
    - So it's not very often, which means this process would only run once a quarter. And that does change my answer. 
    - Amazon EC2 charges per second or per hour, so if we have an instance running all the time to serve a request that happens once per quarter, that seems like a lost opportunity to optimize for cost. We would be spending money on a resource we rarely use. It certainly would work but maybe not the best fit for this use case. we could automate the process of starting and stopping the instance when needed, but instead, what about using AWS Lambda? Bingo. AWS Lambda is the correct answer for this one. There are a few reasons:
        - to address your concern on cost, AWS Lambda only charges you for the compute you consume when the code is actually running. And the code is run in response to triggers or a direct invocation. 
        - the goal is to have someone upload an inventory document to S3, which should kick off the process of updating the database. AWS Lambda has triggers that run your Lambda function's code. AWS Lambda integrates with many AWS services to act as triggers and Amazon S3 is one of them.
        - create an AWS Lambda function, configure a put event as the trigger from Amazon S3. Then when the inventory is uploaded to Amazon S3 it will trigger the Lambda function to run and the code in the function will parse the inventory document and add each item into the database.


- Let's say you have an application currently hosted in your on-premises data center which needs to be migrated to AWS. It's currently running on Linux servers in the data center and you want to **minimize the amount of refactoring needed** to migrate to AWS. It's important that this workload is elastic and can support varying demand. What compute option would you choose? 
    - Considering the fact that minimizing refactoring is an important aspect of this workload, I would architect a solution using Amazon EC2 as the compute service. 
    - EC2 instances can be launched from Linux-based AMIs and the application could be hosted on the EC2 instance the same way it would be hosted on a Linux server on premises. 
    - Amazon EC2 also has the ability to scale in or out based on demand. So I think EC2 is the best service for this one.
    - process behind eliminating the other compute services:
        - AWS Lambda could work, but you can't just upload the same code you would have run on an Amazon EC2 instance into a Lambda function. There would be a decent amount of refactoring in order to take advantage of that service. 
        - Same idea with any of the AWS container services like ECS or EKS. Again, you'd have some amount of rework required to migrate to using containers. Therefore, Amazon EC2 is the best option for this migration. 


- Imagine a scenario where you are planning to write a brand new application using **micro-services or a service-oriented design.** And you want to architect the application where it can scale up or down quickly, and you want to **lower the risk of deploying new changes to production.** Which AWS compute service would you use? 
    - AWS container services like Amazon ECS or Amazon EKS.
    - using containers makes it easier to support microservices or service-oriented designs. 
    - Containers boot up quickly so scaling is quicker than with EC2 instances. And the use of containers helps with code portability, meaning if I write the code on my laptop and I run it in a container, then I test it in QA in a container, I can then expect that the same container would behave the same way once deployed to production, thus reducing the risk of any issues that might occur because of environmental issues.
